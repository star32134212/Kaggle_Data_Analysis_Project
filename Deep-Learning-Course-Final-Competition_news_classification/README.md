DL Final Competition Report 
===
##### 學生：0513404 姜林寬

##### Public Score: **0.92321**  
##### Rank:62/144(截至比賽結束前兩小時)  
##### 執行方式：直接執行
### 實作過程
這個競賽是新聞分類的題目，屬於NLP的一環，一開始我就直接用jieba的斷詞把train data的title分詞，然後跟keyword混在一起做embedding，再塞進LSTM，經過一些微調最後得到了0.84416的score，一開始覺得還行，但後來名次就一直往後掉使得我必須找到一個更好的方法，於是上網找NLP做這類題目相關的文章來看。最後在一篇中國人寫的文章中看到他使用不同方法做新聞分類這個題目，令他驚訝的是他用單純的貝氏分類器這種較不複雜的作法竟然得到了比他第一版的LSTM還要好的結果，於是我仿照了貝氏分類的核心觀念跟一些前面做LSTM得到的一些對於資料處理影響結果的小結論自己做了一個類似的分類器，馬上得到了0.91263的score，在經過一些研究又改了幾次最終以0.92321的結果收工，雖然名次只能在差不多中段，但看了許多文章後我覺得如果還有更多時間以及增加對於其他類似統計分類方法的了解，也許可以再往前爬一些。

### 實作原理
1. 首先我用jieba把train data的title做斷詞，再加上每個title的keyword，可以得到某個label所對應的一個word pool，我去統計每個單詞在各個分類中出現過幾次建成一個字典。

2. 接著餵進test data，test data的title斷詞後加上keyword一樣可以得到一些詞，用這些詞去算各label字典中出現的次數然後除以label字典值的加總，可以得到(n,10)的矩陣，n是title斷詞出的詞數加上keyword詞數的和。

3. 設定參數與normalization，為了不讓某個單詞影響過大，對該單詞所代表的那行(1,10)vector做normalization，我分別做了softmax跟同除該行總合兩種做法，實驗證明後者效果較佳。

4. 為了不讓title或keyword影響過大，分別給他們加上一個參考權重w1和w2，然後將(n,10)矩陣依照column加總，某row是title取出的字則乘以w1，是keyword取出的字則乘以w2，可以得到一個(1,10)的矩陣，最後看哪一類分數較高就選哪行。

### 結論
下圖是隨機取出train data 5000筆data答錯的confused matrix，label=row predict=column，可以看出6與7最容易搞混，也就是軍事與國際，我有把答錯的新聞拉出來看，蠻多用人腦也判斷不太出來的，軍事與國際混淆的大都是國家之間的戰爭，例如美國與中東各國，畢竟國與國之間發生的戰爭本來就算是國際事務，也算是軍事新聞，在train data沒有明確的判斷標準的情況下此分類器也很難判斷，但只要是確定只符合一個分類的新聞，此分類器都可以分出來。因此根據資料label的正確率，也許可以得到更佳的score也說不定。  
![](https://i.imgur.com/BLikg4R.png)  

我有寫一個news_analysis的function，可以看看到底錯在哪，如下圖這篇新聞，正確答案是科技，但實際上分到汽車也沒有什麼不對，畢竟是在討論行車記錄器。另外可以特別注意的是若是兩類都可以的話，從最後給出的分數來看，此分類器確實能找出最佳的兩類，正確答案的科技為第二高分。這類的例子是錯誤中最多的。  
![](https://i.imgur.com/JHoh3dR.png)  
同類型例子二：最常見的就是這種軍事新聞，就算給人分有時也會分到國際，所以分類起給這兩類也給了22、23差不多的分數  
![](https://i.imgur.com/qIM7oQU.png)  

還有一種新聞也無法判斷，像是下面這種，不可思議的經歷跟答案的科技也毫無關係，看上去也想不到是分哪類，keyword也沒有提供，自然是分不出來。  
![](https://i.imgur.com/8jfOpT9.png)  

然後訓練資料中也可以找到一些本來就標錯的data，像是下面這篇毫無疑問就是在討論王者榮耀，關鍵字中也可以看到不知火舞、英雄聯盟、玩家、遊戲等字，但訓練資料卻給了科技這類，這類的例子甚至蠻多個的。  
![](https://i.imgur.com/LS8WlcV.png)  
同類型例子二  
![](https://i.imgur.com/QZyT03H.png)  
同類型例子三  
![](https://i.imgur.com/yCJ810K.png)  



